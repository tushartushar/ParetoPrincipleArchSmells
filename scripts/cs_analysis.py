# This script analyzes the raw output generated by designite_runner.py and generates csv (raw_cs.csv & cyclicFile_cs.csv)

import glob
import os
import re
from collections import Counter

import pandas as pd
from pandas.errors import EmptyDataError

# Setting option to hide warnings
pd.options.mode.chained_assignment = None


### Read csv file and create pandas DataFrame
def read_file(filePath, columnList, duplicateFlag=True):
    if os.path.exists(filePath):
        try:
            dataFrame = pd.read_csv(filePath, usecols=columnList) ### .fillna(value = 'Empty_cell')
            dataFrame = dataFrame.dropna()
            if not dataFrame.empty:
                if duplicateFlag:
                    return dataFrame
                else:
                    return dataFrame.drop_duplicates()
            else:
                return None
        except EmptyDataError:
            return None
    else:
        return None


### Extract from column ['Cause'] a list of namespaces that are dependent to namespaceToExclude
def extract_namespaces(row, strToReplace, namespaceToExclude, type):
    if row.endswith('.'):
        row = row[:-1]

    if type == 1:  # Cyclic Dependency & Scattered Functionality
        namespaces = row.replace(strToReplace, '')
    elif type == 2:  # Dense Structure
        rowList = row.split(strToReplace)
        namespaces = rowList[1]

        stopWords = ['\' to: ', '\' from: ']
        for word in stopWords:
            namespaces = namespaces.replace(word, '\' ')
        namespaces = namespaces.replace('from: ', '')

    namespaceList = namespaces.split('\' ')
    if namespaceToExclude in namespaceList:
        namespaceList.remove(namespaceToExclude)

    if type == 2:
        namespaceList = list(set(namespaceList))
    return namespaceList


### Initialize dictionary which will contain the calculated metrics
# keys: namespaces
# values: list of 8 metrics with zero values
def initialize_dict(namespaceData):
    namespaceList = namespaceData['Namespace'].unique()
    return dict((namespace, [0] * 8) for namespace in namespaceList)


### Create dataFrame with counts of each smell type per namespace [and total smells]
# Note: countSmellDf contains only the architecture smells found in the specific project
def count_smells(smellData):
    if len(smellData) > 0:
        countSmellDf = smellData.groupby('Namespace')['Architecture smell'].value_counts().unstack().fillna(0)
    else:
        countSmellDf = pd.DataFrame([''])
    countSmellDf['Total'] = countSmellDf.sum(axis=1)
    return countSmellDf


### Create a dictionary with additional count of smells per namespace - extracted from column ['Cause']
# key: namespace
# value: count of smells of type: smellType [Cyclic Dependency or Scattered Functionality]
def find_missing_smells(smellData, smellType, toolMessage):
    if smellType in ('Cyclic Dependency', 'Scattered Functionality'):
        type = 1
    elif smellType == 'Dense Structure':
        type = 2

    filteredData = smellData[(smellData['Architecture smell'] == smellType)]
    filteredData['Namespace'] = filteredData.apply(
        lambda x: extract_namespaces(x['Cause'], toolMessage, x['Namespace'], type), axis=1)

    return Counter(filteredData['Namespace'].sum())


### Create a separate file with namespaces involved in each Cyclic Dependency architecture smell
def export_cyclic(smellData, cyclicMessage, repoName):
    cyclicData = smellData[(smellData['Architecture smell'] == 'Cyclic Dependency')]
    cyclicData['Namespace list'] = cyclicData.apply(
        lambda x: extract_namespaces(x['Cause'], cyclicMessage, None, 1), axis=1)

    finalDataset = cyclicData[['Namespace list']]
    finalDataset.insert(0, 'Repository', repoName)
    finalDataset['Length'] = finalDataset.apply(lambda x: len(x['Namespace list']), axis=1)
    finalDataset['Counted'] = 'N'
    finalDataset.insert(0, 'Index', range(1, len(finalDataset) + 1))

    finalDataset['Namespace list'] = finalDataset['Namespace list'].apply(clean_list)
    export_data(finalDataset, cyclicFile, False)


def clean_list(list_):
    # print(list_)
    mylist = str(list_)
    mylist = mylist.replace(', ', ' ')
    mylist = mylist.replace('[', '')
    mylist = mylist.replace(']', '')

    return mylist


### Update the initialized dictionary based on dataFrame containing smell data
def update_dict(countSmellDf, finalDict, archSmells):
    # countSmellDf to dictionary
    tempDict = {key: row.tolist() for key, row in countSmellDf.iterrows()}

    for smell in archSmells:
        smellIndex = archSmells[smell]  # index of metric in final dictionary

        if smell in countSmellDf.columns:
            indexTempDict = countSmellDf.columns.get_loc(smell)  # index of metric in tempDict

            for namespace in tempDict:
                if not str(namespace) == "0":
                    if namespace == '<All namespaces included>':
                        for key in finalDict:
                            finalDict[key][smellIndex] += tempDict[namespace][indexTempDict]
                    elif any(namespace in i for i in finalDict.keys()):
                        finalDict[namespace][smellIndex] += tempDict[namespace][indexTempDict]

    return finalDict


### Update final dictionary with the metrics by adding the missing counts from column ['Cause']
def add_missing_smells(smellData, dictionary, repoName):
    smellsDetected = smellData['Architecture smell'].unique()

    if 'Cyclic Dependency' in smellsDetected:
        # Cyclic Dependency
        cyclicMessage = (
            'The tool detected the smell in this component because this component participates in a cyclic dependency. '
            'The participating components in the cycle are: '
        )

        cyclicData = find_missing_smells(smellData, 'Cyclic Dependency', cyclicMessage)
        export_cyclic(smellData, cyclicMessage, repoName)

        for namespace in cyclicData:
            dictionary[namespace][0] += cyclicData[namespace]  # Cyclic dependency smell metric
            dictionary[namespace][7] += cyclicData[namespace]  # Total architecture smells metric

    if 'Scattered Functionality' in smellsDetected:
        # Scattered Functionality
        scatteredMessage = (
            'The tool detected the smell in this component because a set of two or more components realizes the same high-level architectural concern. '
            'Following components realize the same concern: '
        )

        scatteredData = find_missing_smells(smellData, 'Scattered Functionality', scatteredMessage)

        for namespace in scatteredData:
            dictionary[namespace][5] += scatteredData[namespace]  # Scattered functionality smell metric
            dictionary[namespace][7] += scatteredData[namespace]  # Total architecture smells metric

    if 'Dense Structure' in smellsDetected:
        # Dense Structure
        denseMessage = 'All the dependencies among components: '

        denseData = find_missing_smells(smellData, 'Dense Structure', denseMessage)

        for namespace in denseData:
            dictionary[namespace][6] += denseData[namespace]  # Dense Structure smell metric
            dictionary[namespace][6] = 1 if dictionary[namespace][6] > 0 else 0
            dictionary[namespace][7] = 0
            for i in range(0, 7):
                dictionary[namespace][7] += dictionary[namespace][i]  # Total architecture smells metric

    return dictionary


### Parse repo to calculate metrics
def analyze_repository(repositoryPath, projectList):
    namespaceList = []
    smellList = []

    for project in projectList:
        projectPath = os.path.join(repositoryPath, project)
        namespaceRaw = read_file(projectPath + r'_NamespaceMetrics.csv', ['Namespace'], False)
        namespaceList.append(namespaceRaw)

        smellRaw = read_file(projectPath + r'_ArchSmells.csv',
                             ['Architecture smell', 'Project', 'Namespace', 'Cause'])
        smellList.append(smellRaw)


    repoName = os.path.basename(os.path.dirname(projectPath))
    namespaceData = pd.concat(namespaceList).drop_duplicates()
    namespaceData.insert(0, 'Repository', repoName)

    smellData = pd.concat(smellList)

    if namespaceData is not None:
        columnList = ['Cyclic Dependency', 'Unstable Dependency', 'Ambiguous Interface',
                      'God Component', 'Feature Concentration', 'Scattered Functionality',
                      'Dense Structure', 'Total Architecture Smells']

        metricsDict = initialize_dict(namespaceData)

        ### Filter test/sample packages
        namespaceData = namespaceData[
            namespaceData['Namespace'].str.contains('test|sample', flags=re.IGNORECASE, regex=True) == False]
        smellData = smellData[
            smellData['Namespace'].str.contains('test|sample', flags=re.IGNORECASE, regex=True) == False]

        if smellData is not None:
            countSmellDf = count_smells(smellData)
            metricsDict = update_dict(countSmellDf, metricsDict, archSmells)
            metricsDict = add_missing_smells(smellData, metricsDict, repoName)
            metricsDf = pd.DataFrame([([k] + v) for k, v in metricsDict.items()],
                                     columns=(['Namespace'] + columnList))
        else:
            # Create an empty dataframe with the packages and zero values to all metrics - needed for merging
            namespaceList = namespaceData['Namespace'].unique()
            metricsDf = pd.DataFrame(index=namespaceList, columns=columnList).reset_index()
            metricsDf.columns = ['Namespace'] + columnList
            metricsDf = metricsDf.fillna(0)

        return pd.merge(namespaceData, metricsDf, on='Namespace')


### Export results to csv [mode: appending]
def export_data(dataFrame, outputFile, headerFlag):
    dataFrame.to_csv(outputFile, header=headerFlag, index=False, mode='a')


### Parse all repos in a directory
def parse_repositories(path):
    # Prepare file for Cyclic Dependency data
    with open(cyclicFile, 'w') as writer:
        writer.write('Index,Repository,Namespace list,Length,Counted\n')

    for folder in [f for f in glob.glob(path + '**/**/', recursive=True)]:
        projectList = []
        for file in os.listdir(folder):
            if file.endswith('_NamespaceMetrics.csv'):
                project = file.rsplit('_', 1)[0]
                if project not in projectList:
                    projectList.append(project)

        if len(projectList) != 0:
            print('Analyzing repository: ' + os.path.basename(os.path.dirname(folder)))
            finalDataset = analyze_repository(folder, projectList)
            if finalDataset is not None:
                if os.path.exists(outputFile):
                    export_data(finalDataset, outputFile, False)
                else:
                    export_data(finalDataset, outputFile, True)
            else:
                logList.append(folder)
                print('Error in exporting data from path: ' + folder)

# Define variables

projectPath = r'/path/data/designite_out'
outputFile = r'/path/data/results/raw_cs.csv'
logFile = r'/path/data/results/log.txt'
cyclicFile = r'/path/data/results/cyclicFile_cs.csv'

logList = []

archSmells = {'Cyclic Dependency': 0,
              'Unstable Dependency': 1,
              'Ambiguous Interface': 2,
              'God Component': 3,
              'Feature Concentration': 4,
              'Scattered Functionality': 5,
              'Dense Structure': 6,
              'Total': 7
              }

if __name__ == "__main__":
    parse_repositories(projectPath)

    # Log errors
    with open(logFile, 'w') as f:
        for error in logList:
            f.write("%s\n" % error)
