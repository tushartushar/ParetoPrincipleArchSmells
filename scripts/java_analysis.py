# This script analyzes the raw output generated by designitejava_runner.py and generates csv (raw_java.csv & cyclicFile.csv)

import glob
import os
from collections import Counter

import pandas as pd
from pandas.errors import EmptyDataError

# Setting option to hide warnings
pd.options.mode.chained_assignment = None


### Read csv file and create pandas DataFrame
def read_file(filePath, columnList, duplicateFlag=True):
    if os.path.exists(filePath):
        try:
            dataFrame = pd.read_csv(filePath, usecols=columnList)
            if not dataFrame.empty:
                if duplicateFlag:
                    return dataFrame
                else:
                    return dataFrame.drop_duplicates()
            else:
                return None
        except EmptyDataError:
            return None
    else:
        return None


### Check if there is only one project analyzed and return the project name
def find_project_name(packageData):
    if len(packageData['Project Name'].unique()) == 1:
        return packageData['Project Name'].unique()[0]


### Extract from column ['Cause of the Smell'] a list of packages that are dependent to packageToExclude
def extract_packages(row, strToReplace, packageToExclude, type):
    if row.endswith('.'):
        row = row[:-1]

    if type == 1:  # Cyclic Dependency & Scattered Functionality
        packages = row.replace(strToReplace, '')
    elif type == 2:  # Dense Structure
        rowList = row.split(strToReplace)
        packages = rowList[1]

        stopWords = [' to: ', '; from: ']
        for word in stopWords:
            packages = packages.replace(word, '; ')
        packages = packages.replace('from: ', '')

    packageList = packages.split('; ')
    if packageToExclude in packageList:
        packageList.remove(packageToExclude)

    if type == 2:
        packageList = list(set(packageList))
    return packageList


### Initialize dictionary which will contain the calculated metrics
# keys: packages
# values: list of 8 metrics with zero values
def initialize_dict(packageData):
    packageList = packageData['Package Name'].unique()
    return dict((package, [0] * 8) for package in packageList)


### Create dataFrame with counts of each smell type per package [and total smells]
# Note: countSmellDf contains only the architecture smells found in the specific project
def count_smells(smellData):
    countSmellDf = smellData.groupby('Package Name')['Architecture Smell'].value_counts().unstack().fillna(0)
    countSmellDf['Total'] = countSmellDf.sum(axis=1)
    return countSmellDf


### Create a dictionary with additional count of smells per package - extracted from column ['Cause of the smell']
# key: package
# value: count of smells of type: smellType [Cyclic Dependency or Scattered Functionality]
def find_missing_smells(smellData, smellType, toolMessage):
    if smellType in ('Cyclic Dependency', 'Scattered Functionality'):
        type = 1
    elif smellType == 'Dense Structure':
        type = 2

    filteredData = smellData[(smellData['Architecture Smell'] == smellType)]
    filteredData['Package list'] = filteredData.apply(
        lambda x: extract_packages(x['Cause of the Smell'], toolMessage, x['Package Name'], type), axis=1)

    return Counter(filteredData['Package list'].sum())


### Create a separate file with packages involved in each Cyclic Dependency architecture smell
def export_cyclic(smellData, cyclicMessage):
    cyclicData = smellData[(smellData['Architecture Smell'] == 'Cyclic Dependency')]
    cyclicData['Package list'] = cyclicData.apply(
        lambda x: extract_packages(x['Cause of the Smell'], cyclicMessage, None, 1), axis=1)

    finalDataset = cyclicData[['Project Name', 'Package list']]
    finalDataset['Length'] = finalDataset.apply(lambda x: len(x['Package list']), axis=1)
    finalDataset['Counted'] = 'N'
    finalDataset.insert(0, 'Index', range(1, len(finalDataset) + 1))

    export_data(finalDataset, cyclicFile, False)


### Update the initialized dictionary based on dataFrame containing smell data
def update_dict(countSmellDf, finalDict, archSmells):
    # countSmellDf to dictionary
    tempDict = {key: row.tolist() for key, row in countSmellDf.iterrows()}

    for smell in archSmells:
        smellIndex = archSmells[smell]  # index of metric in final dictionary

        if smell in countSmellDf.columns:
            indexTempDict = countSmellDf.columns.get_loc(smell)  # index of metric in tempDict

            for package in tempDict:
                if package == '<All packages>':
                    for key in finalDict:
                        finalDict[key][smellIndex] += tempDict[package][indexTempDict]
                elif any(package in i for i in finalDict.keys()):
                    finalDict[package][smellIndex] += tempDict[package][indexTempDict]

    return finalDict


### Update final dictionary with the metrics by adding the missing counts from column ['Cause of the smell']
def add_missing_smells(smellData, dictionary):
    smellsDetected = smellData['Architecture Smell'].unique()

    if 'Cyclic Dependency' in smellsDetected:
        # Cyclic Dependency
        cyclicMessage = (
            'The tool detected the smell in this component because this component participates in a cyclic dependency. '
            'The participating components in the cycle are: '
        )

        cyclicData = find_missing_smells(smellData, 'Cyclic Dependency', cyclicMessage)
        export_cyclic(smellData, cyclicMessage)

        for package in cyclicData:
            dictionary[package][0] += cyclicData[package]  # Cyclic dependency smell metric
            dictionary[package][7] += cyclicData[package]  # Total architecture smells metric

    if 'Scattered Functionality' in smellsDetected:
        # Scattered Functionality
        scatteredMessage = (
            'The tool detected the smell in this component because a set of two or more components realizes the same high-level architectural concern. '
            'Following components realize the same concern: '
        )

        scatteredData = find_missing_smells(smellData, 'Scattered Functionality', scatteredMessage)

        for package in scatteredData:
            dictionary[package][5] += scatteredData[package]  # Scattered functionality smell metric
            dictionary[package][7] += scatteredData[package]  # Total architecture smells metric

    if 'Dense Structure' in smellsDetected:
        # Dense Structure
        denseMessage = 'All the dependencies among components: '

        denseData = find_missing_smells(smellData, 'Dense Structure', denseMessage)

        for package in denseData:
            dictionary[package][6] += denseData[package]  # Dense Structure smell metric
            dictionary[package][6] = 1 if dictionary[package][6] > 0 else 0
            dictionary[package][7] = 0
            for i in range(0, 7):
                dictionary[package][7] += dictionary[package][i]  # Total architecture smells metric

    return dictionary


### Parse project to calculate metrics
def analyze_project(projectPath):
    packageData = read_file(os.path.join(projectPath, r'TypeMetrics.csv'), ['Project Name', 'Package Name'], False)
    smellData = read_file(os.path.join(projectPath, r'ArchitectureSmells.csv'),
                          ['Project Name', 'Package Name', 'Architecture Smell', 'Cause of the Smell'])

    if packageData is not None:
        # projectName = find_project_name(packageData)

        columnList = ['Cyclic Dependency', 'Unstable Dependency', 'Ambiguous Interface',
                      'God Component', 'Feature Concentration', 'Scattered Functionality',
                      'Dense Structure', 'Total Architecture Smells']

        metricsDict = initialize_dict(packageData)

        if smellData is not None:
            countSmellDf = count_smells(smellData)
            metricsDict = update_dict(countSmellDf, metricsDict, archSmells)
            metricsDict = add_missing_smells(smellData, metricsDict)
            metricsDf = pd.DataFrame([([k] + v) for k, v in metricsDict.items()],
                                     columns=(['Package Name'] + columnList))
        else:
            # Create an empty dataframe with the packages and zero values to all metrics - needed for merging
            packageList = packageData['Package Name'].unique()
            metricsDf = pd.DataFrame(index=packageList, columns=columnList).reset_index()
            metricsDf.columns = ['Package Name'] + columnList
            metricsDf = metricsDf.fillna(0)

        return pd.merge(packageData, metricsDf, on='Package Name')


### Export results to csv [mode: appending]
def export_data(dataFrame, outputFile, headerFlag):
    dataFrame.to_csv(outputFile, header=headerFlag, index=False, mode='a')


### Parse all projects in a directory
def parse_projects(path):
    # Prepare file for Cyclic Dependency data
    with open(cyclicFile, 'w') as writer:
        writer.write('Index,Project Name,Package list,Length,Counted\n')

    counter = 0
    for projectPath in os.listdir(path):
        cur_paroject_path = os.path.join(path, projectPath)
        if not os.path.isdir(cur_paroject_path):
            continue
        counter += 1
        print('Analyzing project: ' + projectPath)

        finalDataset = analyze_project(cur_paroject_path)
        if finalDataset is not None:
            if counter != 1:
                export_data(finalDataset, outputFile, False)
            else:
                export_data(finalDataset, outputFile, True)
        else:
            logList.append(cur_paroject_path)
            print('Error in exporting data from path: ' + cur_paroject_path)


# Define variables

folderPath = r'/path/data/designitejava_out'
outputFile = r'/path/data/results/raw_java.csv'
logFile = r'/path/data/results/log.txt'
cyclicFile = r'/path/data/results/cyclicFile.csv'

logList = []

archSmells = {'Cyclic Dependency': 0,
              'Unstable Dependency': 1,
              'Ambiguous Interface': 2,
              'God Component': 3,
              'Feature Concentration': 4,
              'Scattered Functionality': 5,
              'Dense Structure': 6,
              'Total': 7
              }

if __name__ == "__main__":
    parse_projects(folderPath)

    # Log errors
    with open(logFile, 'w') as f:
        for error in logList:
            f.write("%s\n" % error)
